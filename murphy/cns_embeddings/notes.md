# cns embeddings — cat murphy, sept. 24

well, evidently i wasn't smart enough to do the embeddings exercise — which is kind of ironic given that i was probably the most excited about using them LOL. all that to say, you’re only getting a description of my general understanding of embeddings and my thoughts on potential use cases because i cant actually answer the question. 

at their most basic, i would describe embeddings as a (poorly named) code system that uses numeric values to represent and “map” non-numeric ideas. in other words, embeddings are floating point numbers assigned to text based on relative context — word to vector. the closer the numbers, the stronger the association. so, for instance, if you had a dataset that contained the words “panda, dog, cat, milk, ice cream, sneakers.” i’m obviously oversimplifying this, but if you were to assign floating point numbers to those things, panda, dog and cat “go together,” so their values would be closer together. cat also “goes with” milk, but milk doesn’t necessarily “go with” dog or panda, so milk would be numerically closer to cat than to dog or panda. milk “goes with” ice cream, and ice cream and milk are both animal products, so ice cream’s floating point number would be closest to milk’s but still near cat, dog and panda. sneakers, meanwhile, is seemingly random in this context, so its floating point number is likely to be much more isolated. the key here is context. visually, dog, panda and cat would be clustered together, milk might be on the outskirts of that cluster nearest to cat, ice cream would be close to milk but not to the animal cluster, and sneakers would be off in no-man’s land. all of at least, i think … but who knows — i have no idea what im talking about lol. but i think its basically a computer’s way of semantically analyzing words and correlating them numerically.

well, we both know my fave potential use case for embeddings re: autocratic speech. but i’m going to try to think of some others. my primary thought is using embeddings to analyze news bias. i don’t really know if even i understand what i’m proposing, so bear with me. basically, i think this could be used to look for associations between news topics and source gender — ooh, or title. i’m not sure if that makes sense. but like, in stories about doctors, are we citing more men? in stories about business, are we talking to or about more men or women? what about science? or tech? so, essentially, are the words “doctor” and “business” and “science” and “technology” more associated with “man” than “woman.” for our purposes, i wonder if we could do that on the sourcing side. like, if the articles talk about environmental concerns, do we cite more experts and officials or community members? what about public health? data centers? tax increases? also, if the stories were tagged, what topics were more likely to be associated with “breaking news.” i think this might help us figure out what is there in an effort to see what isn’t — i.e. where the coverage gaps exist. but idk i have no idea what i’m doing lol.